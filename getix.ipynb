{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Urls to parse\n",
    "URLs that take too long to return data:\n",
    "- https://xbrlus.github.io/cafr/samples/8/va-c-bris-20160630.xhtml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    urls = ['https://xbrlus.github.io/cafr/samples/10/va-o-albe-20170630.xhtml',\n",
    "            'https://xbrlus.github.io/cafr/samples/9/va-t-ashl-20170630.xhtml', \n",
    "            'https://xbrlus.github.io/cafr/samples/8/va-c-bris-20160630.xhtml',\n",
    "            'https://xbrlus.github.io/cafr/samples/6/ga-20190116.htm',\n",
    "            'https://xbrlus.github.io/cafr/samples/1/StPete_StmtNetPos_iXBRL_20190116.htm',\n",
    "            'https://xbrlus.github.io/cafr/samples/2/VABeach_StmtNetPos_iXBRL_20190116.htm',\n",
    "            'https://xbrlus.github.io/cafr/samples/7/ut-20190117.htm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://xbrlus.github.io/cafr/samples/3/Alexandria-2018-Statements.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/4/FallsChurch-2018-Statements.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/5/Loudoun-2018-Statements.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/6/ga-20190116.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/1/StPete_StmtNetPos_iXBRL_20190116.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/2/VABeach_StmtNetPos_iXBRL_20190116.htm',\n",
    "        'https://xbrlus.github.io/cafr/samples/7/ut-20190117.htm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "**BeautifulSoup**: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# In Python 3.7, dict is automatically ordered, but to allow for people using previous versions,\n",
    "# need to use an OrderedDict or the results will be messy.\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_fields(path = 'config.csv'):\n",
    "    ''' \n",
    "    If the config CSV file exists, it is used to determine what to output.\n",
    "    If config file doesn't exist, raises exception.\n",
    "    \n",
    "    CSV Format:\n",
    "    \n",
    "    Output Field Name,Input Field Names (a;b;c)\n",
    "    Document Title,cafr:DocumentTitle\n",
    "    \n",
    "    Returns a dictionary with the output field name as the key and a list of input fields as the value.\n",
    "    \n",
    "    {'Document Title': ['cafr:DocumentTitle'],\n",
    "     'Name of Government': ['cafr:NameOfGovernment']}\n",
    "    '''\n",
    "    df = pd.read_csv(path)\n",
    "    fields = OrderedDict()\n",
    "    for row in df.itertuples(index=False):\n",
    "        fields[row[0]] = row[1].split(';')\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_data(data, fields):\n",
    "    ''' Given a dictionary of data and a dictionary of configuration info, returns dictionary conforming to the configuration. '''\n",
    "    configured = OrderedDict()\n",
    "\n",
    "    # Determine how many entries each column must have, for missing fields.\n",
    "    #row_count = len(data.values[0])\n",
    "    \n",
    "    # TODO: Support multiple input fields -- need more info on what should happen.\n",
    "    for name, input_fields in fields.items():\n",
    "        for field in input_fields:\n",
    "            if field in data:\n",
    "                configured[name] = data[field]\n",
    "    return configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numeric(iterable, downcast='signed'):\n",
    "    ''' Fixes up problems with converting strings to numbers, then uses pd.to_numeric() to do the conversion. '''\n",
    "    for index, item in enumerate(iterable):\n",
    "        if isinstance(item, str):\n",
    "            # Numeric conversions can't handle commas.\n",
    "            new_item = item.replace(',', '')\n",
    "            iterable[index] = new_item\n",
    "    return pd.to_numeric(iterable, downcast=downcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_numeric in module pandas.core.tools.numeric:\n",
      "\n",
      "to_numeric(arg, errors='raise', downcast=None)\n",
      "    Convert argument to a numeric type.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arg : list, tuple, 1-d array, or Series\n",
      "    errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
      "        - If 'raise', then invalid parsing will raise an exception\n",
      "        - If 'coerce', then invalid parsing will be set as NaN\n",
      "        - If 'ignore', then invalid parsing will return the input\n",
      "    downcast : {'integer', 'signed', 'unsigned', 'float'} , default None\n",
      "        If not None, and if the data has been successfully cast to a\n",
      "        numerical dtype (or if the data was numeric to begin with),\n",
      "        downcast that resulting data to the smallest numerical dtype\n",
      "        possible according to the following rules:\n",
      "    \n",
      "        - 'integer' or 'signed': smallest signed int dtype (min.: np.int8)\n",
      "        - 'unsigned': smallest unsigned int dtype (min.: np.uint8)\n",
      "        - 'float': smallest float dtype (min.: np.float32)\n",
      "    \n",
      "        As this behaviour is separate from the core conversion to\n",
      "        numeric values, any errors raised during the downcasting\n",
      "        will be surfaced regardless of the value of the 'errors' input.\n",
      "    \n",
      "        In addition, downcasting will only occur if the size\n",
      "        of the resulting data's dtype is strictly larger than\n",
      "        the dtype it is to be cast to, so if none of the dtypes\n",
      "        checked satisfy that specification, no downcasting will be\n",
      "        performed on the data.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    ret : numeric if parsing succeeded.\n",
      "        Return type depends on input.  Series if Series, otherwise ndarray\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Take separate series and convert to numeric, coercing when told to\n",
      "    \n",
      "    >>> import pandas as pd\n",
      "    >>> s = pd.Series(['1.0', '2', -3])\n",
      "    >>> pd.to_numeric(s)\n",
      "    0    1.0\n",
      "    1    2.0\n",
      "    2   -3.0\n",
      "    dtype: float64\n",
      "    >>> pd.to_numeric(s, downcast='float')\n",
      "    0    1.0\n",
      "    1    2.0\n",
      "    2   -3.0\n",
      "    dtype: float32\n",
      "    >>> pd.to_numeric(s, downcast='signed')\n",
      "    0    1\n",
      "    1    2\n",
      "    2   -3\n",
      "    dtype: int8\n",
      "    >>> s = pd.Series(['apple', '1.0', '2', -3])\n",
      "    >>> pd.to_numeric(s, errors='ignore')\n",
      "    0    apple\n",
      "    1      1.0\n",
      "    2        2\n",
      "    3       -3\n",
      "    dtype: object\n",
      "    >>> pd.to_numeric(s, errors='coerce')\n",
      "    0    NaN\n",
      "    1    1.0\n",
      "    2    2.0\n",
      "    3   -3.0\n",
      "    dtype: float64\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    pandas.DataFrame.astype : Cast argument to a specified dtype.\n",
      "    pandas.to_datetime : Convert argument to datetime.\n",
      "    pandas.to_timedelta : Convert argument to timedelta.\n",
      "    numpy.ndarray.astype : Cast a numpy array to a specified type.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick hack replacement for BeautifulSoup, to work around whatever problem we're having there.\n",
    "def tags_from_html(name, html):\n",
    "    tags = []\n",
    "    results = re.findall(f'(<\\s*{name}.*?>(.*?)<\\s*/\\s*{name}>)', html, flags = re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    for element, content in results:\n",
    "        tag = {'name': name}\n",
    "        tag['content'] = content\n",
    "        \n",
    "        atts = OrderedDict()\n",
    "        att_results = re.findall(f'(\\S+)=[\"\\']?((?:.(?![\"\\']?\\s+(?:\\S+)=|[>\"\\']))+.)[\"\\']?', element)\n",
    "        for att, value in att_results:\n",
    "            atts[att.lower()] = value   # Lower-casing attribute name to avoid case errors in the HTML.\n",
    "        tag['attributes'] = atts\n",
    "        tags.append(tag)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context definitions\n",
    "Need to get a description for each context. A context element looks like this:\n",
    "\n",
    "       <xbrli:context id=\"_ctx9\">\n",
    "          <xbrli:entity><xbrli:identifier scheme=\"http://www.govwiki.info\">47210100100000</xbrli:identifier></xbrli:entity>\n",
    "          <xbrli:period><xbrli:instant>2018-06-30</xbrli:instant></xbrli:period>\n",
    "          <xbrli:scenario>\n",
    "             <xbrldi:explicitMember dimension=\"cafr:FinancialReportingEntityAxis\">cafr:PrimaryGovernmentActivitiesMember</xbrldi:explicitMember>\n",
    "             <xbrldi:explicitMember dimension=\"cafr:BasisOfAccountingAxis\">cafr:ModifiedAccrualBasisOfAccountingMember</xbrldi:explicitMember>\n",
    "             <xbrldi:explicitMember dimension=\"cafr:ActivityTypeAxis\">cafr:GovernmentalTypeActivityMember</xbrldi:explicitMember>\n",
    "             <xbrldi:explicitMember dimension=\"cafr:ClassificationOfFundTypeAxis\">cafr:GeneralFundMember</xbrldi:explicitMember>\n",
    "             <xbrldi:explicitMember dimension=\"cafr:MagnitudeAxis\">cafr:MajorMember</xbrldi:explicitMember>\n",
    "          </xbrli:scenario>\n",
    "       </xbrli:context>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual data\n",
    "Data looks like this:\n",
    "\n",
    "        <td id=\"_NETPOSITION_B10\" style=\"text-align:right;width:114px;\">$&#160;&#160;&#160;&#160;&#160;&#160;&#160;<ix:nonFraction name=\"cafr:CashAndCashEquivalents\" contextRef=\"_ctx3\" id=\"NETPOSITION_B10\" unitRef=\"ISO4217_USD\" decimals = \"0\" format=\"ixt:numdotdecimal\">336,089,928</ix:nonFraction>&#160;</td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XbrliDocument:\n",
    "    def __init__(self, path = None, url = None):\n",
    "        if path:\n",
    "            with open(path,'r') as source:\n",
    "                try:\n",
    "                    html = source.read()\n",
    "                except Exception as e:\n",
    "                    print(f'*** Error: Unable to read {path}: {e}')\n",
    "                    raise e\n",
    "        elif url:\n",
    "            try:\n",
    "                html = requests.get(url).text\n",
    "            except Exception as e:\n",
    "                print(f'*** Error: Unable to read {url}: {e}')\n",
    "                raise e\n",
    "        else:\n",
    "            raise Exception(\"Need a path or url argument!\")\n",
    "        \n",
    "        self.contexts = self._contexts_from_html(html)\n",
    "        self.ix_fields = self._ix_fields_from_html(html)\n",
    "    \n",
    "    def _contexts_from_html(self, html):\n",
    "        contexts = OrderedDict()   # id: text description\n",
    "        for tag in tags_from_html('xbrli:context', html):\n",
    "            text = ''\n",
    "            members = []\n",
    "            for member in tags_from_html('xbrldi:explicitMember', tag['content']):\n",
    "                try:\n",
    "                    members.append(member['content'])\n",
    "                    members.sort()\n",
    "                except:\n",
    "                    pass\n",
    "            text += ' '.join(members)    \n",
    "            contexts[tag['attributes']['id']] = text \n",
    "        return contexts\n",
    "    \n",
    "    def _ix_fields_from_html(self, html):\n",
    "        ix_fields = OrderedDict()   # name (context description): [text]\n",
    "        for ix_name in ('ix:nonNumeric', 'ix:nonFraction'):\n",
    "            for tag in tags_from_html(ix_name, html):\n",
    "                try:\n",
    "                    context = tag['attributes']['contextref']\n",
    "                    \n",
    "                    try:\n",
    "                        description = self.contexts[context]\n",
    "                    except:\n",
    "                        description = context\n",
    "                        print(f'*** Error: document missing context info for {context}, using context name instead.')\n",
    "\n",
    "                    # If there is description text, put it in parenthesis (if empty string, no parenthesis).\n",
    "                    if description: description = f' ({description})'\n",
    "\n",
    "                    name = tag['attributes']['name']\n",
    "                    text = tag['content']\n",
    "\n",
    "                    ix_fields[f'{name}{description}'] = text \n",
    "                except Exception as e:\n",
    "                    print(f\"*** Exception: {type(e)}: {e}\")\n",
    "                    print(tag)\n",
    "        return ix_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(paths=None):\n",
    "    ''' For development, pass a list of paths and urls will be skipped. '''\n",
    "    fields = OrderedDict()\n",
    "    try:\n",
    "        fields = config_fields()\n",
    "        print(f'Config file (config.csv) found.')\n",
    "    except:\n",
    "        print(f'Config file (config.csv) not found, will output all fields as found in documents.')\n",
    "\n",
    "    data = OrderedDict()\n",
    "    docs = []\n",
    "    \n",
    "    if paths:\n",
    "        for path in paths:\n",
    "            print(f'Loading {path}...')\n",
    "            try:\n",
    "                doc = XbrliDocument(path=path)\n",
    "                docs.append(doc)\n",
    "            except:\n",
    "                pass\n",
    "    else:\n",
    "        for url in urls:\n",
    "            print(f'Downloading {url}...')\n",
    "            try:\n",
    "                doc = XbrliDocument(url=url)\n",
    "                docs.append(doc)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # Because docs can have missing fields, and for the spreadsheet all docs must have entries for all fields,\n",
    "    # first need to figure out what all the fields from all the docs are, before processing the data.\n",
    "    for doc in docs:\n",
    "        for key in doc.ix_fields:\n",
    "            data.setdefault(key, [])\n",
    "\n",
    "    # Now can process the docs.\n",
    "    for doc in docs:\n",
    "        for key, value in doc.ix_fields.items():\n",
    "            data_list = data.setdefault(key, [])\n",
    "            data_list.append(value)\n",
    "\n",
    "        # And finally add blank entries for any missing fields.\n",
    "        for key, value in data.items():\n",
    "            if key not in doc.ix_fields:\n",
    "                value.append('')\n",
    "    \n",
    "    if fields:\n",
    "        data = configure_data(data, fields)\n",
    "\n",
    "    # Use Pandas to turn data dictionary into csv.\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # DEBUG: This is a hack assuming which columns are numeric.\n",
    "    # TODO: Probably want the config file to specify the column format.\n",
    "    # Not slicing here to avoid potential complications (http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy)\n",
    "    for col in df.columns[5:]:\n",
    "        df[col] = to_numeric(df[col])\n",
    "\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    df.to_excel('output.xlsx', index=False)\n",
    "\n",
    "    print(f\"Processed data for {len(docs)} entities, wrote out {len(data)} fields. See output.xlsx and output.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    from mydir import mydir\n",
    "    from pathlib import Path\n",
    "    \n",
    "    paths = [str(path) for path in Path('test_data').iterdir() if '.htm' in str(path)]\n",
    "    main(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file (config.csv) found.\n",
      "Loading test_data/Alexandria-2018-Statements.htm...\n",
      "Loading test_data/ga-20190116.htm...\n",
      "Loading test_data/FallsChurch-2018-Statements.htm...\n",
      "Loading test_data/ut-20190117.htm...\n",
      "Loading test_data/Loudoun-2018-Statements.htm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 5 entities, wrote out 12 fields. See output.xlsx and output.csv.\n"
     ]
    }
   ],
   "source": [
    "#main()\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
